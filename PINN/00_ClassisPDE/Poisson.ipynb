{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson Equation is defined as:\n",
    "\n",
    "$$-\\nabla^2U=1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\software\\Anaconda\\envs\\yolov5\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary python modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define nn\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(1, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = torch.tanh(self.fc1(inputs))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "def poisson_loss(u_pred, x_pred):\n",
    "    u_pred = u_pred.sum()\n",
    "    u_x = torch.autograd.grad(u_pred, x_pred, create_graph=True)[0]\n",
    "    u_x = u_x.sum()\n",
    "    u_xx = torch.autograd.grad(u_x, x_pred, create_graph=True)[0]\n",
    "    f_pred = u_xx\n",
    "    return torch.mean(torch.square(f_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define boundary condition\n",
    "def boundary_condition(x):\n",
    "    return np.sin(np.pi * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "def train_PINN(x_data, u_data, num_epochs, device):\n",
    "\n",
    "    model = PINN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    x_data_tensor = torch.tensor(x_data, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    u_data_tensor = torch.tensor(u_data, dtype=torch.float32, device=device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        u_pred = model(x_data_tensor)\n",
    "        loss = poisson_loss(u_pred, x_data_tensor)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mg:\\Program\\AI4S\\PINN\\00_ClassisPDE\\Poisson.ipynb 单元格 8\u001b[0m line \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trained_model \u001b[39m=\u001b[39m train_PINN(x_train, u_train, num_epochs, device)\n",
      "\u001b[1;32mg:\\Program\\AI4S\\PINN\\00_ClassisPDE\\Poisson.ipynb 单元格 8\u001b[0m line \u001b[0;36mtrain_PINN\u001b[1;34m(x_data, u_data, num_epochs, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m u_pred \u001b[39m=\u001b[39m model(x_data_tensor)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m poisson_loss(u_pred, x_data_tensor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32mg:\\Program\\AI4S\\PINN\\00_ClassisPDE\\Poisson.ipynb 单元格 8\u001b[0m line \u001b[0;36mpoisson_loss\u001b[1;34m(u_pred, x_pred)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpoisson_loss\u001b[39m(u_pred, x_pred):\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     u_pred \u001b[39m=\u001b[39m u_pred\u001b[39m.\u001b[39msum()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     u_xx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(u_pred, x_pred, create_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39;49m], x_pred, create_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     f_pred \u001b[39m=\u001b[39m u_xx\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Program/AI4S/PINN/00_ClassisPDE/Poisson.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39msquare(f_pred))\n",
      "File \u001b[1;32mg:\\software\\Anaconda\\envs\\yolov5\\lib\\site-packages\\torch\\autograd\\__init__.py:261\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    256\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39monly_inputs argument is deprecated and is ignored now \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m(defaults to True). To accumulate gradient for other \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mparts of the graph, please use torch.autograd.backward.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    260\u001b[0m grad_outputs_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_outputs, \u001b[39mlen\u001b[39m(t_outputs))\n\u001b[1;32m--> 261\u001b[0m grad_outputs_ \u001b[39m=\u001b[39m _make_grads(t_outputs, grad_outputs_, is_grads_batched\u001b[39m=\u001b[39;49mis_grads_batched)\n\u001b[0;32m    263\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[1;32mg:\\software\\Anaconda\\envs\\yolov5\\lib\\site-packages\\torch\\autograd\\__init__.py:67\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mrequires_grad:\n\u001b[0;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mnumel() \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m     new_grads\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mones_like(out, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format))\n\u001b[0;32m     69\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "x_train = np.linspace(0, 1, 100).reshape(-1, 1) # (100,) -> (100, 1)\n",
    "u_train = boundary_condition(x_train)\n",
    "\n",
    "# append boundary condition\n",
    "x_train = np.vstack((x_train, [[0], [1]])) # (100, 1) -> (102, 1)\n",
    "u_train = np.vstack((u_train, [[boundary_condition(0)], [boundary_condition(1)]]))\n",
    "\n",
    "num_epochs = 1000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = train_PINN(x_train, u_train, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([5.0, 7.0], requires_grad=True)\n",
    "y = x**2\n",
    "\n",
    "loss1 = torch.mean(y)\n",
    "\n",
    "h1 = torch.autograd.grad(y[0], x, retain_graph = True, create_graph=True)\n",
    "h2 = torch.autograd.grad(y[1], x, retain_graph = True, create_graph=True)\n",
    "loss2 = torch.mean(h1[0] - h2[0])\n",
    "\n",
    "loss = loss1 + loss2\n",
    "\n",
    "result = torch.autograd.grad(loss, x)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0  x =  1.600000023841858  y =  2.9600000381469727\n",
      "i =  100  x =  3.259258973820067e-10  y =  6.029625687631324e-10\n",
      "i =  200  x =  6.639225599928508e-20  y =  1.2282564516434385e-19\n",
      "i =  300  x =  1.35243404871145e-29  y =  2.502002824606578e-29\n",
      "i =  400  x =  2.7549569847579833e-39  y =  5.096666848491185e-39\n",
      "i =  500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  1900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  2900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  3900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  4900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  5900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  6900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  7900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  8900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9000  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9100  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9200  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9300  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9400  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9500  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9600  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9700  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9800  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n",
      "i =  9900  x =  2.802596928649634e-45  y =  2.802596928649634e-45\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def fxy(x, y):\n",
    "    return x ** 2 + y ** 2\n",
    "\n",
    "x = torch.tensor((2.0,), requires_grad=True)\n",
    "y = torch.tensor((3.7,), requires_grad=True)\n",
    "\n",
    "lr = 0.1\n",
    "num_epochs = 10000\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    pred = fxy(x, y)\n",
    "    pred.backward()\n",
    "\n",
    "    x.data -= lr * x.grad.data\n",
    "    y.data -= lr * y.grad.data\n",
    "\n",
    "    x.grad.zero_()\n",
    "    y.grad.zero_()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"i = \", i, \" x = \", x.item(), \" y = \", y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
